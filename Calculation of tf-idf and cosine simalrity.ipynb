{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4bfe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1793874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents\n",
    "doc1 = 'Information Retrieval System'\n",
    "doc2 = 'Information about the Human Resource System'\n",
    "doc3 = 'Resources allocated to Faculty of Computing Information Centre'\n",
    "doc4 = 'Ranked Retrieval Model with High Accuracy'\n",
    "doc5 = 'Boolean Retrieval Model has Several Problems'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9a2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1 part a\n",
    "#creating the bag of words\n",
    "bagOfWords_doc1 = doc1.split(' ')\n",
    "bagOfWords_doc2 = doc2.split(' ')\n",
    "bagOfWords_doc3 = doc3.split(' ')\n",
    "bagOfWords_doc4 = doc4.split(' ')\n",
    "bagOfWords_doc5 = doc5.split(' ')\n",
    "\n",
    "# finding the unique words\n",
    "unique_words = set(bagOfWords_doc1).union(set(bagOfWords_doc2).union(set(bagOfWords_doc3).union(set(bagOfWords_doc4).union(set(bagOfWords_doc5)))))\n",
    "unique_words\n",
    "\n",
    "#Creating  a dictionary of words to calculate their occurence in each document in the corpus\n",
    "numOfWords_doc1 = dict.fromkeys(unique_words, 0) \n",
    "for word in bagOfWords_doc1:\n",
    "    numOfWords_doc1[word] += 1\n",
    "    \n",
    "numOfWords_doc2 = dict.fromkeys(unique_words, 0)\n",
    "for word in bagOfWords_doc2:\n",
    "    numOfWords_doc2[word] += 1\n",
    "    \n",
    "numOfWords_doc3 = dict.fromkeys(unique_words, 0)\n",
    "for word in bagOfWords_doc3:\n",
    "    numOfWords_doc3[word] += 1\n",
    "    \n",
    "numOfWords_doc4 = dict.fromkeys(unique_words, 0)\n",
    "for word in bagOfWords_doc4:\n",
    "    numOfWords_doc4[word] += 1\n",
    "    \n",
    "numOfWords_doc5 = dict.fromkeys(unique_words, 0)\n",
    "for word in bagOfWords_doc5:\n",
    "    numOfWords_doc5[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3046cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61eb156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Information': 1, 'System': 1, 'Retrieval': 1},\n",
       " {'Information': 1,\n",
       "  'System': 1,\n",
       "  'the': 1,\n",
       "  'about': 1,\n",
       "  'Resource': 1,\n",
       "  'Human': 1},\n",
       " {'Faculty': 1,\n",
       "  'of': 1,\n",
       "  'Information': 1,\n",
       "  'Resources': 1,\n",
       "  'Centre': 1,\n",
       "  'to': 1,\n",
       "  'allocated': 1,\n",
       "  'Computing': 1},\n",
       " {'High': 1,\n",
       "  'Ranked': 1,\n",
       "  'with': 1,\n",
       "  'Retrieval': 1,\n",
       "  'Model': 1,\n",
       "  'Accuracy': 1},\n",
       " {'Retrieval': 1,\n",
       "  'Problems': 1,\n",
       "  'has': 1,\n",
       "  'Several': 1,\n",
       "  'Boolean': 1,\n",
       "  'Model': 1}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1 part a\n",
    "#method to calculate the term frequency\n",
    "def termFrequency(term,document):\n",
    "    tfDict = {}\n",
    "    NormDoc = document.lower().split()\n",
    "    return NormDoc.count(term.lower()) \n",
    "\n",
    "def calc_tf(documents):\n",
    "    tf_doc = []\n",
    "    for txt in documents:\n",
    "        sentence = txt.split()\n",
    "        tf_dict= dict.fromkeys(set(sentence), 0)\n",
    "        for word in sentence:\n",
    "            tf_dict[word] = termFrequency(word, txt)\n",
    "        tf_doc.append(tf_dict)\n",
    "    return tf_doc\n",
    "\n",
    "\n",
    "tf_doc=calc_tf([doc1,doc2,doc3,doc4,doc5])\n",
    "tf_doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c595bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Information': 3,\n",
       " 'Retrieval': 3,\n",
       " 'System': 2,\n",
       " 'about': 1,\n",
       " 'the': 1,\n",
       " 'Human': 1,\n",
       " 'Resource': 1,\n",
       " 'Resources': 1,\n",
       " 'allocated': 1,\n",
       " 'to': 1,\n",
       " 'Faculty': 1,\n",
       " 'of': 1,\n",
       " 'Computing': 1,\n",
       " 'Centre': 1,\n",
       " 'Ranked': 1,\n",
       " 'Model': 2,\n",
       " 'with': 1,\n",
       " 'High': 1,\n",
       " 'Accuracy': 1,\n",
       " 'Boolean': 1,\n",
       " 'has': 1,\n",
       " 'Several': 1,\n",
       " 'Problems': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1 part a\n",
    "#method to find the document frequency of terms\n",
    "def document_frequency(term, allDocs):\n",
    "    numOfDocsWithThisTerm = 0\n",
    "    for doc in range (0, len(allDocs)):\n",
    "        if term.lower() in allDocs[doc].lower().split():\n",
    "            numOfDocsWithThisTerm = numOfDocsWithThisTerm + 1\n",
    "    return numOfDocsWithThisTerm\n",
    "    \n",
    "def calc_df(documents):\n",
    "    idf_dict = {}\n",
    "    for doc in documents:\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            idf_dict[word] = document_frequency(word, documents)\n",
    "    return idf_dict\n",
    "\n",
    "df_dict = calc_df([doc1,doc2,doc3,doc4,doc5])\n",
    "df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8040dd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Information': 1.0, 'System': 1.0, 'Retrieval': 1.0},\n",
       " {'Information': 1.0,\n",
       "  'System': 1.0,\n",
       "  'the': 1.0,\n",
       "  'about': 1.0,\n",
       "  'Resource': 1.0,\n",
       "  'Human': 1.0},\n",
       " {'Faculty': 1.0,\n",
       "  'of': 1.0,\n",
       "  'Information': 1.0,\n",
       "  'Resources': 1.0,\n",
       "  'Centre': 1.0,\n",
       "  'to': 1.0,\n",
       "  'allocated': 1.0,\n",
       "  'Computing': 1.0},\n",
       " {'High': 1.0,\n",
       "  'Ranked': 1.0,\n",
       "  'with': 1.0,\n",
       "  'Retrieval': 1.0,\n",
       "  'Model': 1.0,\n",
       "  'Accuracy': 1.0},\n",
       " {'Retrieval': 1.0,\n",
       "  'Problems': 1.0,\n",
       "  'has': 1.0,\n",
       "  'Several': 1.0,\n",
       "  'Boolean': 1.0,\n",
       "  'Model': 1.0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b). Question 1 part b\n",
    "#method to calculate the log-term frequency\n",
    "def logTermFreq(term,document):\n",
    "    LTF_Dict = {}\n",
    "    normDoc = document.lower().split()\n",
    "    if normDoc.count(term.lower())> 0: \n",
    "      return 1 + math.log(normDoc.count(term.lower())) \n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "def calc_LTF(documents):\n",
    "    LTF_Doc = []\n",
    "    for txt in documents:\n",
    "        sentence = txt.split()\n",
    "        ltf_dict= dict.fromkeys(set(sentence), 0)\n",
    "        for word in sentence:\n",
    "            ltf_dict[word] = logTermFreq(word, txt)\n",
    "        LTF_Doc.append(ltf_dict)\n",
    "    return LTF_Doc\n",
    "\n",
    "\n",
    "ltf_doc=calc_LTF([doc1,doc2,doc3,doc4,doc5])\n",
    "ltf_doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4f3467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Information': 0.5108256237659907,\n",
       " 'Retrieval': 0.5108256237659907,\n",
       " 'System': 0.9162907318741551,\n",
       " 'about': 1.6094379124341003,\n",
       " 'the': 1.6094379124341003,\n",
       " 'Human': 1.6094379124341003,\n",
       " 'Resource': 1.6094379124341003,\n",
       " 'Resources': 1.6094379124341003,\n",
       " 'allocated': 1.6094379124341003,\n",
       " 'to': 1.6094379124341003,\n",
       " 'Faculty': 1.6094379124341003,\n",
       " 'of': 1.6094379124341003,\n",
       " 'Computing': 1.6094379124341003,\n",
       " 'Centre': 1.6094379124341003,\n",
       " 'Ranked': 1.6094379124341003,\n",
       " 'Model': 0.9162907318741551,\n",
       " 'with': 1.6094379124341003,\n",
       " 'High': 1.6094379124341003,\n",
       " 'Accuracy': 1.6094379124341003,\n",
       " 'Boolean': 1.6094379124341003,\n",
       " 'has': 1.6094379124341003,\n",
       " 'Several': 1.6094379124341003,\n",
       " 'Problems': 1.6094379124341003}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1 part b\n",
    "#method to calculate the inverse document frequency\n",
    "def InverseDocumentFrequency(term, allDocuments):\n",
    "    numOfDocsWithThisTerm = 0\n",
    "    for doc in range (0, len(allDocuments)):\n",
    "        if term.lower() in allDocuments[doc].lower().split():\n",
    "            numOfDocsWithThisTerm = numOfDocsWithThisTerm + 1\n",
    "    if numOfDocsWithThisTerm > 0:\n",
    "        return math.log(float(len(allDocuments)) / numOfDocsWithThisTerm)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def calcIDF(documents):\n",
    "    idf_dict = {}\n",
    "    for doc in documents:\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            idf_dict[word] = InverseDocumentFrequency(word, documents)\n",
    "    return idf_dict\n",
    "\n",
    "idf_dict = calcIDF([doc1,doc2,doc3,doc4,doc5])\n",
    "idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e99301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information</th>\n",
       "      <th>System</th>\n",
       "      <th>Retrieval</th>\n",
       "      <th>the</th>\n",
       "      <th>about</th>\n",
       "      <th>Resource</th>\n",
       "      <th>Human</th>\n",
       "      <th>Faculty</th>\n",
       "      <th>of</th>\n",
       "      <th>Resources</th>\n",
       "      <th>...</th>\n",
       "      <th>Computing</th>\n",
       "      <th>High</th>\n",
       "      <th>Ranked</th>\n",
       "      <th>with</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Problems</th>\n",
       "      <th>has</th>\n",
       "      <th>Several</th>\n",
       "      <th>Boolean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Information    System  Retrieval       the     about  Resource     Human  \\\n",
       "0     0.510826  0.916291   0.510826       NaN       NaN       NaN       NaN   \n",
       "1     0.510826  0.916291        NaN  1.609438  1.609438  1.609438  1.609438   \n",
       "2     0.510826       NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "3          NaN       NaN   0.510826       NaN       NaN       NaN       NaN   \n",
       "4          NaN       NaN   0.510826       NaN       NaN       NaN       NaN   \n",
       "\n",
       "    Faculty        of  Resources  ...  Computing      High    Ranked  \\\n",
       "0       NaN       NaN        NaN  ...        NaN       NaN       NaN   \n",
       "1       NaN       NaN        NaN  ...        NaN       NaN       NaN   \n",
       "2  1.609438  1.609438   1.609438  ...   1.609438       NaN       NaN   \n",
       "3       NaN       NaN        NaN  ...        NaN  1.609438  1.609438   \n",
       "4       NaN       NaN        NaN  ...        NaN       NaN       NaN   \n",
       "\n",
       "       with     Model  Accuracy  Problems       has   Several   Boolean  \n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "3  1.609438  0.916291  1.609438       NaN       NaN       NaN       NaN  \n",
       "4       NaN  0.916291       NaN  1.609438  1.609438  1.609438  1.609438  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1 part b\n",
    "#method to calculate the tf-idf scores\n",
    "def calc_tfidf(ltf_doc, idf_dict): \n",
    "    tf_idf = [] \n",
    "    for index in range(0,len(ltf_doc)):\n",
    "      tfidf_doc={}\n",
    "      for word, val in ltf_doc[index].items(): \n",
    "          tfidf_doc[word] = val * idf_dict[word] \n",
    "      tf_idf.append(tfidf_doc)\n",
    "    return tf_idf\n",
    "\n",
    "tfidf = calc_tfidf(ltf_doc,idf_dict)\n",
    "tfidf\n",
    "\n",
    "df=pd.DataFrame([tfidf[0],tfidf[1],tfidf[2],tfidf[3],tfidf[4]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b5cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc  Information  Retrieval\n",
      "0  0.0     0.510826   0.510826\n",
      "1  1.0     0.510826   0.000000\n",
      "2  2.0     0.510826   0.000000\n",
      "3  3.0     0.000000   0.510826\n",
      "4  4.0     0.000000   0.510826\n"
     ]
    }
   ],
   "source": [
    "# method used to calculate the tf-idf score on all documents for a given query\n",
    "query = \"Information Retrieval\"\n",
    "def computeTFIDFWithAllDocs(documents , query):\n",
    "    tfidf = []\n",
    "    index = 0\n",
    "    query_tokens = query.split()\n",
    "    df = pd.DataFrame(columns=['doc'] + query_tokens) \n",
    "    for doc in documents:\n",
    "        df['doc'] = np.arange(0 , len(documents))\n",
    "        doc_num = ltf_doc[index] \n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            for text in query_tokens:\n",
    "                if(text == word):\n",
    "                    idx = sentence.index(word)\n",
    "                    tf_idf_score = doc_num[word] * idf_dict[word]\n",
    "                    tfidf.append(tf_idf_score)\n",
    "                    df.iloc[index, df.columns.get_loc(word)] = tf_idf_score \n",
    "        index += 1\n",
    "    df.fillna(0 , axis=1, inplace=True)\n",
    "    return tfidf , df\n",
    "            \n",
    "documents = [doc1, doc2, doc3,doc4,doc5]\n",
    "tf_idf , df = computeTFIDFWithAllDocs(documents , query)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee21075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Information': 1.0, 'Retrieval': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "def calc_queryTF(query):\n",
    "    QueryNormTF = {}\n",
    "    tokens = query.split()\n",
    "    for word in tokens:\n",
    "        QueryNormTF[word] = logTermFreq(word , query)\n",
    "    return QueryNormTF\n",
    "QueryNormTF = calc_queryTF(query)\n",
    "print(QueryNormTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ca71b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Information': 0.5108256237659907, 'Retrieval': 0.5108256237659907}\n"
     ]
    }
   ],
   "source": [
    "#method for calculating the idf score for the query\n",
    "def calcQueryIDF(query):\n",
    "    IDFDictQuery = {}\n",
    "    sentence = query.split()\n",
    "    documents = [doc1, doc2, doc3,doc4,doc5]\n",
    "    for word in sentence:\n",
    "        IDFDictQuery[word] = InverseDocumentFrequency(word ,documents)\n",
    "    return IDFDictQuery\n",
    "IDFDictQuery = calcQueryIDF(query)\n",
    "print(IDFDictQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "732be107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Information': 0.5108256237659907, 'Retrieval': 0.5108256237659907}\n"
     ]
    }
   ],
   "source": [
    "#method for calculating the tf-idf score for the query \n",
    "def calcQueryTFIDF(query):\n",
    "    tfidfDictQuery = {}\n",
    "    sentence = query.split()\n",
    "    for word in sentence:\n",
    "        tfidfDictQuery[word] = QueryNormTF[word] * IDFDictQuery[word]\n",
    "    return tfidfDictQuery\n",
    "tfidfDictQuery = calcQueryTFIDF(query)\n",
    "print(tfidfDictQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4abdb3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.521886\n",
      "Name: Information, dtype: float64\n",
      "1    0.369029\n",
      "Name: Information, dtype: float64\n",
      "2    0.369029\n",
      "Name: Information, dtype: float64\n",
      "3    0.369029\n",
      "Name: Information, dtype: float64\n",
      "4    0.369029\n",
      "Name: Information, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 3 part a\n",
    "#Method to find the similarity between the query and the documents using Euclidian Distance\n",
    "\n",
    "def EuclidianDistance(tfidfDictQuery, df , query , doc_num):\n",
    "    Qrymod = 0\n",
    "    Docmod = 0\n",
    "    tokens = query.split()\n",
    "   \n",
    "    for keyword in tokens:\n",
    "        Qrymod += tfidfDictQuery[keyword] * tfidfDictQuery[keyword]\n",
    "        Docmod += df[keyword][df['doc'] == doc_num] * df[keyword][df['doc'] == doc_num]\n",
    "    Qrymod = np.sqrt(Qrymod)\n",
    "    Docmod = np.sqrt(Docmod)\n",
    "    ed = Qrymod * Docmod\n",
    "     \n",
    "    return ed\n",
    "\n",
    "\n",
    "for i in range(0,5):\n",
    "  Euclid_value= EuclidianDistance(tfidfDictQuery, df , query , i)\n",
    "  print(Euclid_value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af416bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "Name: Information, dtype: float64\n",
      "1    0.707107\n",
      "Name: Information, dtype: float64\n",
      "2    0.707107\n",
      "Name: Information, dtype: float64\n",
      "3    0.707107\n",
      "Name: Information, dtype: float64\n",
      "4    0.707107\n",
      "Name: Information, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Question 3 part b\n",
    "#Method to calculate the similarity between the documents and the query using cosine similarity\n",
    "def cosine(tfidfDictQuery, df , query , doc_num):\n",
    "    DotProd = 0\n",
    "    Qrymod = 0\n",
    "    Docmod = 0\n",
    "    tokens = query.split()\n",
    "   \n",
    "    for keyword in tokens:\n",
    "        DotProd += tfidfDictQuery[keyword] * df[keyword][df['doc'] == doc_num]\n",
    "        #||Query||\n",
    "        Qrymod += tfidfDictQuery[keyword] * tfidfDictQuery[keyword]\n",
    "        #||Document||\n",
    "        Docmod += df[keyword][df['doc'] == doc_num] * df[keyword][df['doc'] == doc_num]\n",
    "    Qrymod = np.sqrt(Qrymod)\n",
    "    Docmod = np.sqrt(Docmod)\n",
    "    #implement formula\n",
    "    denominator = Qrymod * Docmod\n",
    "    cosineSimilarity = DotProd/denominator\n",
    "     \n",
    "    return cosineSimilarity\n",
    "\n",
    "for i in range(0,5):\n",
    "  cos_sim=cosine(tfidfDictQuery, df , query ,i)\n",
    "  print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b117a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Document1', 'Document2', 'Document3', 'Document4', 'Document5']\n",
      "[1.0000000000000002, 0.7071067811865476, 0.7071067811865476, 0.7071067811865476, 0.7071067811865476]\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "# Method used to rank the documents using the cosine similarity\n",
    "\n",
    "from collections import Iterable\n",
    "def flatten(lis): #define the flatten function\n",
    "     for item in lis:\n",
    "        if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "             for x in flatten(item):\n",
    "                yield x\n",
    "        else:        \n",
    "             yield item\n",
    "\n",
    "def document_ranking_with_cosine(data):\n",
    "    cos_simi =[]\n",
    "    for doc_num in range(0 , len(data)):\n",
    "        cos_simi.append(cosine(tfidfDictQuery, df , query , doc_num).tolist()) \n",
    "    return cos_simi\n",
    "\n",
    "documents = [doc1, doc2, doc3,doc4,doc5]\n",
    "similarity = document_ranking_with_cosine(documents)\n",
    "doc_names = [\"Document1\", \"Document2\",\"Document3\",\"Document4\",\"Document5\"]\n",
    "print(doc_names)\n",
    "print(list(flatten(similarity))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c8f196b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Document1', 'Document2', 'Document3', 'Document4', 'Document5']\n",
      "[0.5218856357918269, 0.36902887207225366, 0.36902887207225366, 0.36902887207225366, 0.36902887207225366]\n"
     ]
    }
   ],
   "source": [
    "# Method used to rank the documents using the euclidian distance\n",
    "def document_ranking_with_euclidian(data):\n",
    "    cos_simin =[]\n",
    "    for doc_num in range(0 , len(data)):\n",
    "        cos_simin.append(EuclidianDistance(tfidfDictQuery, df , query , doc_num).tolist()) \n",
    "    return cos_simin\n",
    "\n",
    "documents = [doc1, doc2, doc3,doc4,doc5]\n",
    "similarity = document_ranking_with_euclidian(documents)\n",
    "doc_names = [\"Document1\", \"Document2\",\"Document3\",\"Document4\",\"Document5\"]\n",
    "print(doc_names)\n",
    "print(list(flatten(similarity))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9aebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
