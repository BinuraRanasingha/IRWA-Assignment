{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d3e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents\n",
    "Doc1 = 'Information Retrieval System'\n",
    "Doc2 = 'Information about the Human Resource System'\n",
    "Doc3 = 'Resources allocated to Faculty of Computing Information Centre'\n",
    "Doc4 = 'Ranked Retrieval Model with High Accuracy'\n",
    "Doc5 = 'Boolean Retrieval Model has Several Problems'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8b84e58e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bagOfWords1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [119]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#Creating  a dictionary of words to calculate their occurence for each document in the corpus\u001b[39;00m\n\u001b[0;32m     21\u001b[0m numOfWords1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(uniqueWords, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbagOfWords1\u001b[49m:\n\u001b[0;32m     23\u001b[0m     numOfWords1[word] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     24\u001b[0m numOfWords2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(uniqueWords, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bagOfWords1' is not defined"
     ]
    }
   ],
   "source": [
    "#Question 1 part a\n",
    "import math\n",
    "import pandas as pd #importing the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#creating bag of words\n",
    "bagOfWordsDoc1 = Doc1.split(' ')\n",
    "bagOfWordsDoc2 = Doc2.split(' ')\n",
    "bagOfWordsDoc3 = Doc3.split(' ')\n",
    "bagOfWordsDoc4 = Doc4.split(' ')\n",
    "bagOfWordsDoc5 = Doc5.split(' ')\n",
    "\n",
    "\n",
    "#finding the unique words\n",
    "uniqueWords = set(bagOfWordsDoc1).union(set(bagOfWordsDoc2)).union(set(bagOfWordsDoc3)).union(set(bagOfWordsDoc4)).union(set(bagOfWordsDoc5))\n",
    "uniqueWords\n",
    "\n",
    "#Creating  a dictionary of words to calculate their occurence for each document in the corpus\n",
    "\n",
    "numOfWords1 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWords1:\n",
    "    numOfWords1[word] += 1\n",
    "numOfWords2 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWords2:\n",
    "    numOfWords2[word] += 1\n",
    "numOfWords3 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWords3:\n",
    "    numOfWords3[word] += 1\n",
    "numOfWords4 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWords4:\n",
    "    numOfWords4[word] += 1\n",
    "numOfWords5 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWords5:\n",
    "    numOfWords5[word] += 1\n",
    "#Method to calculate the term frequency\n",
    "def cal_tf(docs_list):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():        \n",
    "        tfDict[word] = count\n",
    "        tfDict[word] = count / float(bagOfWordsCount)# calculates the normalized term frequency\n",
    "    return tfDict\n",
    "\n",
    "# Calculating the term frequency for each document\n",
    "tf1 = computeTF(numOfWordsA, bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06470cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'System': 0.3333333333333333,\n",
       "  'Retrieval': 0.3333333333333333,\n",
       "  'Information': 0.3333333333333333},\n",
       " {'about': 0.16666666666666666,\n",
       "  'Resource': 0.16666666666666666,\n",
       "  'Information': 0.16666666666666666,\n",
       "  'System': 0.16666666666666666,\n",
       "  'the': 0.16666666666666666,\n",
       "  'Human': 0.16666666666666666},\n",
       " {'of': 0.125,\n",
       "  'Resources': 0.125,\n",
       "  'Information': 0.125,\n",
       "  'Computing': 0.125,\n",
       "  'Faculty': 0.125,\n",
       "  'Centre': 0.125,\n",
       "  'allocated': 0.125,\n",
       "  'to': 0.125},\n",
       " {'Retrieval': 0.16666666666666666,\n",
       "  'High': 0.16666666666666666,\n",
       "  'Model': 0.16666666666666666,\n",
       "  'Accuracy': 0.16666666666666666,\n",
       "  'with': 0.16666666666666666,\n",
       "  'Ranked': 0.16666666666666666},\n",
       " {'Boolean': 0.16666666666666666,\n",
       "  'Retrieval': 0.16666666666666666,\n",
       "  'Model': 0.16666666666666666,\n",
       "  'Problems': 0.16666666666666666,\n",
       "  'has': 0.16666666666666666,\n",
       "  'Several': 0.16666666666666666}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method to calculate the normalized term frequency\n",
    "def termFreq(term ,document):\n",
    "    normDoc = document.lower().split()\n",
    "    return normDoc.count(term.lower()) / float(len(normDoc))\n",
    "\n",
    "def cal_normtf(documents):\n",
    "    tf_doc = []\n",
    "    for txt in documents:\n",
    "        sentence = txt.split()\n",
    "        normtf = dict.fromkeys(set(sentence),0)\n",
    "        for word in sentence:\n",
    "            normtf[word] = termFreq(word,txt)\n",
    "        tf_doc.append(normtf)\n",
    "        df = pd.DataFrame([normtf])\n",
    "        idx = 0\n",
    "        new_col = [\"Normalized TF\"]\n",
    "        df.insert(loc=idx, column='Term',value=new_col)\n",
    "        #print(df)\n",
    "    return tf_doc\n",
    "\n",
    "tf_doc = cal_normtf([Doc1,Doc2,Doc3,Doc4,Doc5])\n",
    "tf_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "359c8484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Information': 3,\n",
       " 'Retrieval': 3,\n",
       " 'System': 2,\n",
       " 'about': 1,\n",
       " 'the': 1,\n",
       " 'Human': 1,\n",
       " 'Resource': 1,\n",
       " 'Resources': 1,\n",
       " 'allocated': 1,\n",
       " 'to': 1,\n",
       " 'Faculty': 1,\n",
       " 'of': 1,\n",
       " 'Computing': 1,\n",
       " 'Centre': 1,\n",
       " 'Ranked': 1,\n",
       " 'Model': 2,\n",
       " 'with': 1,\n",
       " 'High': 1,\n",
       " 'Accuracy': 1,\n",
       " 'Boolean': 1,\n",
       " 'has': 1,\n",
       " 'Several': 1,\n",
       " 'Problems': 1}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1 part a\n",
    "#Method to calculate document frequency\n",
    "def documentFrequency(term, alldocs):\n",
    "    NumOfDocsWithTerm = 0\n",
    "    for doc in range(0,len(alldocs)):\n",
    "        if term.lower() in alldocs[doc].lower().split():\n",
    "            NumOfDocsWithTerm += 1\n",
    "    return NumOfDocsWithTerm\n",
    "\n",
    "\n",
    "def cal_df(documents):\n",
    "    df_dict = {}\n",
    "    for doc in documents:\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            df_dict[word] = documentFrequency(word, documents)\n",
    "    return df_dict\n",
    "df_dict = cal_df([Doc1, Doc2, Doc3,Doc4,Doc5])\n",
    "cal_df([Doc1, Doc2, Doc3,Doc4,Doc5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b00f5ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Information': 2.6094379124341005,\n",
       " 'Retrieval': 2.6094379124341005,\n",
       " 'System': 2.6094379124341005,\n",
       " 'about': 2.6094379124341005,\n",
       " 'the': 2.6094379124341005,\n",
       " 'Human': 2.6094379124341005,\n",
       " 'Resource': 2.6094379124341005,\n",
       " 'Resources': 2.6094379124341005,\n",
       " 'allocated': 2.6094379124341005,\n",
       " 'to': 2.6094379124341005,\n",
       " 'Faculty': 2.6094379124341005,\n",
       " 'of': 2.6094379124341005,\n",
       " 'Computing': 2.6094379124341005,\n",
       " 'Centre': 2.6094379124341005,\n",
       " 'Ranked': 2.6094379124341005,\n",
       " 'Model': 2.6094379124341005,\n",
       " 'with': 2.6094379124341005,\n",
       " 'High': 2.6094379124341005,\n",
       " 'Accuracy': 2.6094379124341005,\n",
       " 'Boolean': 2.6094379124341005,\n",
       " 'has': 2.6094379124341005,\n",
       " 'Several': 2.6094379124341005,\n",
       " 'Problems': 2.6094379124341005}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1 part b\n",
    "#Method to calculate the inverse document frequency\n",
    "def inverseDocFreq(term,alldoc):\n",
    "    NoOfDocsWithThisTerm = 0\n",
    "    for doc in range (0,len(alldoc)):\n",
    "        if term.lower() in alldoc[doc].lower().split():\n",
    "            NoOfDocsWithThisTerm += 1\n",
    "            \n",
    "        if NoOfDocsWithThisTerm >0:\n",
    "            return 1.0 + math.log(float(len(alldoc)) / NoOfDocsWithThisTerm)\n",
    "        \n",
    "def calc_idf(documents):\n",
    "    idf_dict = {}\n",
    "    for doc in documents:\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            idf_dict[word] = inverseDocFreq(word,documents)\n",
    "    return idf_dict\n",
    "idf_dict = calc_idf([Doc1,Doc2,Doc3,Doc4,Doc5])\n",
    "\n",
    "calc_idf([Doc1,Doc2,Doc3,Doc4,Doc5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03a07d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1 part b\n",
    "#Method to calculate the tf-idf scores\n",
    "def cal_tfidf(document,query):\n",
    "    tfidf = []\n",
    "    index = 0\n",
    "    query_tokens = query.split()\n",
    "    df = pd.DataFrame(columns = ['doc'] + query_tokens)\n",
    "    for doc in documents:\n",
    "        df['doc'] = np.arange(0,len(documents))\n",
    "        doc_num = tf_doc[index]\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            for text in query_tokens:\n",
    "                if(text == word):\n",
    "                    idx = sentence.index(word)\n",
    "                    tfidf_score = doc_num[word] * idf_dict[word]\n",
    "                    tfidf.append(tfidf_score)\n",
    "                    df.iloc[index,df.columns.get_loc(word)] = tfidf_score\n",
    "        index += 1\n",
    "    df.fillna(0, axis = 1, inplace = True)\n",
    "    return tfidf, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da144131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1 part c\n",
    "#method to calculate the normalized vector\n",
    "#def norm_vector(term):\n",
    " #   vector = cal_tfidf(documents, term) #unormalized vector\n",
    "  #  s = math.pow(vector,2) #calculating the squared value of the vector\n",
    "   # norm_vec = vector / math.sqrt(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a629aae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc  Information  Retrieval\n",
      "0  0.0     0.869813   0.869813\n",
      "1  1.0     0.434906   0.000000\n",
      "2  2.0     0.326180   0.000000\n",
      "3  3.0     0.000000   0.434906\n",
      "4  4.0     0.000000   0.434906\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "query = 'Information Retrieval'\n",
    "documents = [Doc1,Doc2,Doc3,Doc4,Doc5]\n",
    "tfidf, df = cal_tfidf(documents,query)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d529b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad25ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
